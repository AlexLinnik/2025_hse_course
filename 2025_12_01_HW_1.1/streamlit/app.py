import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
import pickle
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error as MSE
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
from sklearn.preprocessing import StandardScaler

st.set_page_config(page_title="HW1 Linear Regression Prediction", page_icon="üéØ", layout="wide")

MODEL_DIR = Path(__file__).resolve().parent / "models"

AVAILABLE_MODELS = {
    '–õ–∏–Ω–µ–π–Ω–∞—è': 'linear.pkl',
    '–õ–∏–Ω–µ–π–Ω–∞—è (–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∞—è)': 'linear_scaled.pkl',
    'Lasso (default)': 'lasso.pkl',
    'Lasso (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ)': 'lasso_optimal.pkl',
    'Elastic': 'elastic.pkl',
    'Ridge': 'ridge.pkl'
}

def remove_postfixs(df, column, postfixs):
    for postfix in postfixs:
        df[column] = df[column].str.replace(postfix, '', regex=False)
    return df[column]

@st.cache_resource
def load_model(model_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ pickle"""
    with open(f'{MODEL_DIR}/{model_file}', 'rb') as file:
        model = pickle.load(file)

    return model

def test_empty_values(df, columns):
    for column in columns:
        if df[column].isnull().any():
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª–∏: '{column}' –Ω–µ –≤–µ–∑–¥–µ –∑–∞–ø–æ–ª–Ω–µ–Ω")
            st.stop()

def prepare_features_common(df):
    """–ü—Ä–∏–≤–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."""
    try:
        # –î–µ–ª–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç:
        df_process = df.copy()
        # –ù–µ—Ç —Å–º—ã—Å–ª–∞ —Ç–∞—â–∏—Ç—å —Ñ–∏—á–∏ –∏–∑ –º–æ–¥–µ–ª–∏, —Ç–∞–∫ –∫–∞–∫ —Ç—É—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        # —Ç–∏–ø–æ–≤, —á–∏—Å—Ç–∫–∞ –ø–æ—Å—Ç—Ñ–∏–∫—Å–æ–≤. –ü–æ–≤—Ç–æ—Ä–∏–º –ª–æ–≥–∏–∫—É –∏–∑ –æ–±—É—á–∞–ª–∫–∏:
        if 'torque' in df.columns:        
            df_process = df_process.drop(['torque'], axis = 1)
        df_process['max_power'] = df_process['max_power'].replace('', np.nan)
        df_process['mileage'] = df_process['mileage'].replace('', np.nan)
        
        test_empty_values(df_process, ['seats','mileage','engine','max_power'])
        df_process['seats'] = df_process['seats'].astype(int)
        if 'selling_price' in df.columns:
            df_process = df_process.drop(['selling_price'], axis = 1)       
        df_process['mileage'] = remove_postfixs(df_process, 'mileage', [' kmpl', ' km/kg'])
        df_process['engine'] = remove_postfixs(df_process, 'engine', [' CC'])
        df_process['max_power'] = remove_postfixs(df_process, 'max_power', [' bhp'])

        df_process['max_power'] = df_process['max_power'].astype(float)    
        df_process['mileage'] = df_process['mileage'].astype(float)
        df_process['engine'] = df_process['engine'].astype(int)
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        st.stop()
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏ (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
    # for col in feature_names:
    #    if col in df_proc.columns:
    #        if df_proc[col].dtype in ('object', 'bool'):
    #            df_proc[col] = df_proc[col].astype(str)
                
    return df_process

def get_dummies_with_seats(df):
    df = pd.get_dummies(df, drop_first=True)
    seats_dummies = pd.get_dummies(df['seats'], prefix='seats')
    return pd.concat([df.drop('seats', axis=1), seats_dummies], axis=1)

def use_first_name(df):
    return df['name'].str.split(' ').str[0]

def prepare_features(model_name, scaler, data):
    st.write(f'–ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {model_name}:')
    
    data = prepare_features_common(data)
    st.write('... –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è')
    
    if (model_name != 'Ridge'):
        data = data.select_dtypes(include='number')   
        st.write('... –û—Ç–±—Ä–æ—à–µ–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏') 
    
    if (model_name != '–õ–∏–Ω–µ–π–Ω–∞—è' and model_name != 'Ridge'):
        data_columns = data.columns
        data = pd.DataFrame(scaler.transform(data), columns=data_columns)
        st.write('... –ü—Ä–∏–º–µ–Ω–µ–Ω –ª–∏–Ω–µ–π–Ω—ã–π —Å–∫–∞–ª–ª–µ—Ä')
        
    if (model_name == 'Ridge'):
        st.write('... –ü–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ–ª–µ name')
        data['name'] = use_first_name(data)
        st.write('... –í—ã–¥–µ–ª—è–µ–º dummy –ø—Ä–∏–∑–Ω–∞–∫–∏')
        data = get_dummies_with_seats(data)
        st.write('... –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –º–æ–¥–µ–ª–∏')
        X_train = load_model('ridge_features.pkl')
        X_train, data = X_train.align(data, join='left', axis=1, fill_value=False)
        assert X_train.shape[1] == data.shape[1]
        
        scaler = load_model('scaler_ridge.pkl')
        data_columns = data.columns
        data = data = pd.DataFrame(scaler.transform(data), columns=data_columns)
        st.write('... –ü—Ä–∏–º–µ–Ω–µ–Ω –ª–∏–Ω–µ–π–Ω—ã–π —Å–∫–∞–ª–ª–µ—Ä –Ω–∞ Ridge')        

    
    return data    

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
st.title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π")

selected_option = st.selectbox('–í—ã–±–∏—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:', AVAILABLE_MODELS.keys())
st.write('–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å:', selected_option)

# –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", type=["csv"])

if uploaded_file is None:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª!")
    st.stop()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
data = pd.read_csv(uploaded_file)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∫–∞–ª–µ—Ä
try:
    scaler = load_model('scaler.pkl')
except Exception as e:
    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∫–∞–ª–µ—Ä–∞: {e}")
    st.stop()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
try:
    model = load_model(AVAILABLE_MODELS[selected_option])
except Exception as e:
    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    st.stop()

try:
    X_test = prepare_features(selected_option, scaler, data)    
    if X_test.isna().sum().sum() != 0:        
        st.error(f"‚ùå –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª—è—Ö. –ü—Ä–æ–≤–µ—Ä—Ç—å–µ –∫–æ–ª–æ–Ω–∫–∏ {X_test.columns}")
    
    predictions = model.predict(X_test)    
    data['prediction'] = predictions
except Exception as e:
    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
    st.stop()

if 'selling_price' in data.columns:
    st.subheader(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∫–æ–ª–æ–Ω–∫–∏ selling_price)")
    r2 = r2_score(data['selling_price'], data['prediction'])
    mse = MSE(data['selling_price'], data['prediction'])
    col1, col2 = st.columns(2)
    with col1:
        st.metric("R2 score", r2)
    with col2:
        st.metric("MSE", mse)
    
else:
    st.info("üëà –í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ –Ω–µ—Ç –ø–æ–ª—è selling_price, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ, –µ—Å–ª–∏ —Ö–æ—Ç–∏–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")

st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")

col1, col2 = st.columns(2)
with col1:
    st.metric("–í—Å–µ–≥–æ –º–∞—à–∏–Ω", len(data))
with col2:
    mean = data['prediction'].mean()
    st.metric("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", f"{mean:.1f}")

# –û—Ç–≤–µ—Ç—ã —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏:
st.subheader(f"–ú–æ–¥–µ–ª—å: {selected_option}")
if 'selling_price' in data.columns:
    st.table(data[['name', 'selling_price', 'prediction']])
else: 
    st.table(data[['name', 'prediction']])   

# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ ---
st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
fig, ax = plt.subplots()
ax.barh(X_test.columns, model.coef_)
ax.set_xlabel('–í–µ—Å')
ax.set_title('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏')
st.pyplot(fig)
